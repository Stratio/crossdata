################################
#                              #
#      Catalog options         #
#                              #
################################
crossdata-core.external.config.resource = "core-application.conf"
crossdata-core.external.config.filename = "/etc/sds/crossdata/core-application.conf"
crossdata-core.external.config.filename = ${?crossdata_core_external_config_filename}
## Pluggable catalog (it has to extend org.apache.spark.sql.crossdata.catalog.XDCatalog)
## If there is no catalog class setted, DerbyCatalog will be used

crossdata-core.catalog.caseSensitive = true

#JDBC parameters

####### Example JDBC MySQL ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.MySQLCatalog"
#crossdata-core.catalog.jdbc.driver = "org.mariadb.jdbc.Driver"
#crossdata-core.catalog.jdbc.url = "jdbc:mysql://127.0.0.1:3306/"
#crossdata-core.catalog.jdbc.db.name = "crossdata"
#crossdata-core.catalog.jdbc.db.table = "crossdataTables"
#crossdata-core.catalog.jdbc.db.view = "crossdataViews"
#crossdata-core.catalog.jdbc.db.user = "root"
#crossdata-core.catalog.jdbc.db.pass = ""


####### PostgreSQL ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.PostgreSQLCatalog"
#crossdata-core.catalog.jdbc.driver = "org.postgresql.Driver"
#crossdata-core.catalog.jdbc.url = "jdbc:postgresql://127.0.0.1:5432/"
#crossdata-core.catalog.jdbc.db.name = "crossdata"
#crossdata-core.catalog.jdbc.db.table = "crossdataTables"
#crossdata-core.catalog.jdbc.db.view = "crossdataViews"
#crossdata-core.catalog.jdbc.db.user = "postgres"
#crossdata-core.catalog.jdbc.db.pass = "postgres"


####### Zookeeper Catalog Configuration ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.ZookeeperCatalog"
#crossdata-core.catalog.zookeeper.connectionString = "localhost:2181"
#crossdata-core.catalog.zookeeper.connectionTimeout = 15000
#crossdata-core.catalog.zookeeper.sessionTimeout = 60000
#crossdata-core.catalog.zookeeper.retryAttempts = 5
#crossdata-core.catalog.zookeeper.retryInterval = 10000



#####################################
#                                   #
#      Streaming configuration      #
#                                   #
#####################################

crossdata-core.streaming.catalog.class="org.apache.spark.sql.crossdata.catalog.ZookeeperStreamingCatalog"
crossdata-core.streaming.catalog.zookeeper.connectionString = "localhost:2181"
crossdata-core.streaming.catalog.zookeeper.connectionTimeout = 15000
crossdata-core.streaming.catalog.zookeeper.sessionTimeout = 60000
crossdata-core.streaming.catalog.zookeeper.retryAttempts = 5
crossdata-core.streaming.catalog.zookeeper.retryInterval = 10000

####### Particular formats ###########

# Each connection has three elements separated by ':' and if more connections are needed they have to be added between ','.
#crossdata-core.streaming.kafka.connection = "HOST:CONSUMER_PORT:PRODUCER_PORT,HOST:CONSUMER_PORT:PRODUCER_PORT"

# Each topic has two elements separated by ':' and if more topics are needed they have to be added between ','.
#crossdata-core.streaming.kafka.topic = "TOPIC_NAME:PARTITION_NUMBER,TOPIC_NAME:PARTITION_NUMBER"

# options not mandatory like queryoptions, kafka.options and sparkoptions are passed to a config Map. It is needed to add a key after the parameter name
#crossdata-core.streaming.queryoptions.someKey = "somKafkaValue"
#crossdata-core.streaming.queryoptions.someKey = "somKafkaValue"
#crossdata-core.streaming.kafka.options.someKey = "somKafkaValue"
#crossdata-core.streaming.kafka.options.someKey = "somKafkaValue"
crossdata-core.streaming.sparkoptions.someKey = "somKafkaValue"
#crossdata-core.streaming.sparkoptions.someKey = "somKafkaValue"



####### Example###########
#crossdata-core.streaming.kafka.connection = "localhost:2181:9092"
#crossdata-core.streaming.kafka.topic = "XDTestTopic:1"
#crossdata-core.streaming.kafka.groupId = "XDGroup1"
#crossdata-core.streaming.kafka.partition = "1"
#crossdata-core.streaming.kafka.options.someKey = "someValue"
#crossdata-core.streaming.kafka.options.someKey1 = "someValue1"
#crossdata-core.streaming.kafka.storageLevel = "MEMORY_AND_DISK_SER"

#crossdata-core.streaming.atomicWindow = "5"
#crossdata-core.streaming.maxWindow= "10"
#crossdata-core.streaming.outputFormat = "ROW"
#crossdata-core.streaming.checkpointDirectory = "/stratio/crossdata"
#crossdata-core.streaming.sparkoptions.AppName = "batch-streaming"
#crossdata-core.streaming.sparkoptions.Master = "local[2]"

#crossdata-core.streaming.checkpointDirectory = "/stratio/crossdata"
#crossdata-core.streaming.sparkoptions.AppName = "batch-streaming"
#crossdata-core.streaming.sparkoptions.Master = "local[2]"

#crossdata-core.streaming.sql = "/stratio/crossdata"
#crossdata-core.streaming.alias = "batch-streaming"
#crossdata-core.streaming.window = "local[2]"
#crossdata-core.streaming.queryoptions.someKey = "someValue"
#crossdata-core.streaming.queryoptions.someKey1 = "someValue1"


####### Spark Launcher Configuration ###########
#crossdata-core.streaming.launcher.connectionString = "localhost:2181"
#crossdata-core.streaming.launcher.connectionTimeout = 15000
#crossdata-core.streaming.launcher.sessionTimeout = 60000
#crossdata-core.streaming.launcher.retryAttempts = 5
#crossdata-core.streaming.launcher.retryInterval = 10000


#####################################
#                                   #
#      EphimeralTableOptions        #
#                                   #
#####################################


#crossdata-core.streaming.sparkHome = "/path/to/spark"

#Kafka receiver options
crossdata-core.streaming.receiver.kafka.connection = "localhost:2181:9092"
#crossdata-core.streaming.receiver.kafka.partition = "0"
crossdata-core.streaming.receiver.storageLevel = "MEMORY_AND_DISK_SER"
#crossdata-core.streaming.receiver.kafka.options.someKey = "someValue"

#Streaming options
crossdata-core.streaming.atomicWindow = "5"
crossdata-core.streaming.maxWindow= "10"
crossdata-core.streaming.outputFormat = "ROW"
#The checkpoint directory will be checkpointDirectory/ephemeralTableName
crossdata-core.streaming.checkpointDirectory = "/stratio/crossdata"


#Spark options
crossdata-core.streaming.spark.master = "local[2]"
crossdata-core.streaming.spark.driver.memory = 512M
crossdata-core.streaming.spark.executor.memory = 512M
crossdata-core.streaming.spark.cores.max = 2
#crossdata-core.streaming.spark.executor.cores


####### Spark Launcher Configuration ###########
crossdata-core.streaming.launcher.zookeeper.connectionString = "localhost:2181"
crossdata-core.streaming.launcher.connectionTimeout = 15000
crossdata-core.streaming.launcher.sessionTimeout = 60000
crossdata-core.streaming.launcher.retryAttempts = 5
crossdata-core.streaming.launcher.retryInterval = 10000
crossdata-core.streaming.launcher.jar = "/home/darrollo/Projects/crossdata/streaming/target/crossdata-streaming-${project.version}-jar-with-dependencies.jar"
crossdata-core.streaming.launcher.jars = ["/home/darrollo/Projects/crossdata/server/target/crossdata-server-${project.version}-jar-with-dependencies.jar"]
crossdata-core.streaming.launcher.spark.master = "local[4]"
